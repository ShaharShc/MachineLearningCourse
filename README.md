# MachineLearningCourse
Ben Gurion University "Machine Learning (372.2.5214)" course assignments &amp; solutions

- Assignment & solution 1 (Naive Bayes) - [Notebook](EX1_NB.ipynb)
    In this assignment, I implemented and applied Naive Bayes models to two distinct tasks:
  
    1. **Classifying Digits using Bernoulli Naive Bayes:** Applied the Bernoulli Naive Bayes algorithm to the MNIST dataset, aiming to classify digits (0-9).
    2. **Classifying Text Documents using Multinomial Naive Bayes:** Developed a custom Naive Bayes classifier to categorize text documents from the "20 newsgroups" dataset, comparing its performance to scikit-learn's built-in model.
       
- Assignment & solution 2 (Ensemble Learning) - [Notebook](EX2_Ensemble.ipynb)
  
  In this assignment, I explored the use of the AdaBoost algorithm with Linear SVM weak learners to classify a synthetic dataset. The task involved training models with different numbers of estimators, evaluating performance on train and test sets, and identifying the optimal number of estimators while visualizing the decision boundaries and accuracy trends.
  
- Assignment & solution 3 (Unsupervised Learning) - [Notebook](EX3_Unsupervised_Learning.ipynb)
  
  In this assignment, I explore unsupervised learning techniques by applying K-means clustering and PCA to cluster fake news articles. I perform clustering, and visualize results using PCA. Performance is evaluated through clustering accuracy and optimization of the number of clusters (k) using SSD and Silhouette scores.
  
- Assignment & solution 4 (Clinical Trial Classification) - [Notebook](EX4_Clinical_Trial_Classification.ipynb)
  
  In this assignment, I focused on classifying clinical trial data. Key aspects of the assignment included:

  1. **Data Preparation**: Preprocessing clinical trial data, including handling missing values and encoding categorical features.
  2. **Modeling**: Implementing and evaluating various classification models such as Logistic Regression, Random Forest, and Gradient Boosting.
  3. **Evaluation**: Assessing model performance using metrics like accuracy, precision, recall, F1-score, and ROC-AUC. This involved tuning hyperparameters to improve the classification results.
  4. **Visualization**: Creating visualizations to understand model predictions and feature importance, helping to interpret the results and provide insights into the clinical trial data.
